{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from samyol.predictor import SAMYOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_paths = \"./assets/image1.jpg\"\n",
    "model_path = \"./checkpoints/yolov7-tiny.onnx\"\n",
    "version = \"7\"\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samyol = SAMYOL(\n",
    "    model_path=model_path,\n",
    "    version=version,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[39m=\u001b[39m samyol\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m      2\u001b[0m     input_paths\u001b[39m=\u001b[39;49minput_paths,\n\u001b[0;32m      3\u001b[0m )\n",
      "File \u001b[1;32mc:\\Rim\\VSCode\\rim_jawher_projects\\samyol\\samyol\\predictor.py:51\u001b[0m, in \u001b[0;36mSAMYOL.predict\u001b[1;34m(self, input_paths)\u001b[0m\n\u001b[0;32m     49\u001b[0m outputs \u001b[39m=\u001b[39m yolo_pipeline[\u001b[39m'\u001b[39m\u001b[39minference\u001b[39m\u001b[39m'\u001b[39m](\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_path, preprocessed_data, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     50\u001b[0m obj_det_predictions \u001b[39m=\u001b[39m yolo_pipeline[\u001b[39m'\u001b[39m\u001b[39mpostprocessing\u001b[39m\u001b[39m'\u001b[39m](outputs)\n\u001b[1;32m---> 51\u001b[0m object_segmentation_predictions \u001b[39m=\u001b[39m HuggingFaceSAMModel(preprocessed_data[\u001b[39m2\u001b[39;49m], obj_det_predictions)\u001b[39m.\u001b[39msam_inference(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m preprocessed_data[\u001b[39m2\u001b[39m], object_segmentation_predictions\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "predictions = samyol.predict(\n",
    "    input_paths=input_paths,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RJ\\samyol\\venv\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:65: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "d:\\RJ\\samyol\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m samyol\u001b[39m.\u001b[39;49mdisplay()\n",
      "File \u001b[1;32md:\\RJ\\samyol\\samyol\\predictor.py:63\u001b[0m, in \u001b[0;36mSAMYOL.display\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdisplay\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39m    Display the bounding boxes and masks.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m     original_RGB, object_segmentation_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(input_paths\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39m./assets/image1.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     64\u001b[0m     num_images \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(original_RGB)\n\u001b[0;32m     66\u001b[0m     \u001b[39m# Define the number of rows and columns for the subplots\u001b[39;00m\n",
      "File \u001b[1;32md:\\RJ\\samyol\\samyol\\predictor.py:55\u001b[0m, in \u001b[0;36mSAMYOL.predict\u001b[1;34m(self, input_paths)\u001b[0m\n\u001b[0;32m     49\u001b[0m outputs \u001b[39m=\u001b[39m yolo_pipeline[\u001b[39m'\u001b[39m\u001b[39minference\u001b[39m\u001b[39m'\u001b[39m](\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_path, preprocessed_data, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     50\u001b[0m obj_det_predictions \u001b[39m=\u001b[39m yolo_pipeline[\u001b[39m'\u001b[39m\u001b[39mpostprocessing\u001b[39m\u001b[39m'\u001b[39m](outputs)\n\u001b[0;32m     51\u001b[0m object_segmentation_predictions \u001b[39m=\u001b[39m HuggingFaceSAMModel(\n\u001b[0;32m     52\u001b[0m     preprocessed_data[\u001b[39m2\u001b[39;49m], \n\u001b[0;32m     53\u001b[0m     obj_det_predictions,\n\u001b[0;32m     54\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice\n\u001b[1;32m---> 55\u001b[0m )\u001b[39m.\u001b[39;49msam_inference()\n\u001b[0;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m preprocessed_data[\u001b[39m2\u001b[39m], object_segmentation_predictions\n",
      "File \u001b[1;32md:\\RJ\\samyol\\samyol\\sam_inference.py:84\u001b[0m, in \u001b[0;36mHuggingFaceSAMModel.sam_inference\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[39m# Reshape the tensor to have size (N, 3)\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     reshaped_iou_scores \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39miou_scores\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mt()\n\u001b[1;32m---> 84\u001b[0m     idx_max_iou \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(reshaped_iou_scores\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     86\u001b[0m     object_segmentation_predictions\u001b[39m.\u001b[39mappend({\n\u001b[0;32m     87\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mimage_id\u001b[39m\u001b[39m'\u001b[39m: image_id,\n\u001b[0;32m     88\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mclass_id\u001b[39m\u001b[39m'\u001b[39m: class_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mmasks\u001b[39m\u001b[39m'\u001b[39m: [masks[i, j, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m] \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m (idx_max_iou)]\n\u001b[0;32m     92\u001b[0m         })\n\u001b[0;32m     94\u001b[0m \u001b[39mreturn\u001b[39;00m object_segmentation_predictions\n",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "samyol.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
